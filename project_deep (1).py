"""project deep

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D5RJtGkwrb5rkZpq5xNm0ezx0UR3as2S
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install gradio -q
!pip install torch torchvision pillow -q

# ============================================================================
# CELL 1: IMPORTS AND SETUP
# ============================================================================
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from PIL import Image
import os
import matplotlib.pyplot as plt
import warnings
import gradio as gr
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
from sklearn.metrics import precision_score, recall_score, f1_score
import seaborn as sns
import random

warnings.filterwarnings('ignore')

# Set random seeds for reproducibility
torch.manual_seed(42)
random.seed(42)

# Set device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"‚úÖ Using device: {device}")
print("‚úÖ All libraries imported successfully!")

# ============================================================================
# CELL 2: DATA LOADING FUNCTIONS
# ============================================================================
def load_and_split_data():
    """Load dataset and split into train/val/test sets"""
    dataset_path = "/content/drive/MyDrive/Cancer/Dataset_BUSI_with_GT/Dataset_BUSI_with_GT"
    image_files = []
    labels = []
    class_mapping = {'normal': 0, 'benign': 1, 'malignant': 2}

    print(f"Looking for dataset in: {dataset_path}")

    # Check if path exists
    if not os.path.exists(dataset_path):
        print(f"‚ùå Dataset path does not exist: {dataset_path}")
        print(f"Current working directory: {os.getcwd()}")
        print("Trying to find dataset in common locations...")

        # Try alternative paths
        possible_paths = [
            "./Dataset_BUSI_with_GT",
            "../Dataset_BUSI_with_GT",
            "../../Dataset_BUSI_with_GT",
            "/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT",
            "/content/Dataset_BUSI_with_GT"
        ]

        for path in possible_paths:
            if os.path.exists(path):
                dataset_path = path
                print(f"‚úÖ Found dataset at: {path}")
                break
        else:
            print("‚ùå Could not find dataset. Please check the path.")
            return [], [], [], [], [], []

    # Scan for classes
    for class_name in ['benign', 'malignant', 'normal']:
        class_path = os.path.join(dataset_path, class_name)
        if os.path.exists(class_path):
            class_files = []
            for filename in os.listdir(class_path):
                if filename.lower().endswith(('.png', '.jpg', '.jpeg')):
                    # Skip mask images (containing "mask")
                    if "_mask" not in filename.lower():
                        full_path = os.path.join(class_path, filename)
                        class_files.append(full_path)

            if class_files:
                image_files.extend(class_files)
                labels.extend([class_mapping[class_name]] * len(class_files))
                print(f"‚úÖ Found {len(class_files)} images in class '{class_name}'")
            else:
                print(f"‚ö†Ô∏è No images found in class '{class_name}'")
        else:
            print(f"‚ö†Ô∏è Class folder not found: {class_path}")

    if not image_files:
        print("‚ùå No images found in dataset!")
        print(f"Available folders in {dataset_path}: {os.listdir(dataset_path)}")
        return [], [], [], [], [], []

    # Split data (70% train, 15% val, 15% test)
    dataset_size = len(image_files)
    train_size = int(0.7 * dataset_size)
    val_size = int(0.15 * dataset_size)

    indices = torch.randperm(dataset_size, generator=torch.Generator().manual_seed(42))
    train_indices = indices[:train_size]
    val_indices = indices[train_size:train_size + val_size]
    test_indices = indices[train_size + val_size:]

    train_files = [image_files[i] for i in train_indices]
    train_labels = [labels[i] for i in train_indices]
    val_files = [image_files[i] for i in val_indices]
    val_labels = [labels[i] for i in val_indices]
    test_files = [image_files[i] for i in test_indices]
    test_labels = [labels[i] for i in test_indices]

    print(f"\nüìä Dataset Summary:")
    print(f"Total images: {len(image_files)}")
    print(f"Train set: {len(train_files)}")
    print(f"Validation set: {len(val_files)}")
    print(f"Test set: {len(test_files)}")

    return train_files, train_labels, val_files, val_labels, test_files, test_labels

# Load data immediately when this cell runs
print("üìÇ Loading dataset...")
train_files, train_labels, val_files, val_labels, test_files, test_labels = load_and_split_data()
print("‚úÖ Data loaded successfully!")

# ============================================================================
# CELL 3: DATASET CLASS
# ============================================================================
class BreastCancerDataset(Dataset):
    """Custom Dataset for Breast Cancer Images"""
    def __init__(self, image_files, labels, transform=None):
        self.image_files = image_files
        self.labels = labels
        self.transform = transform

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        img = Image.open(self.image_files[idx]).convert('RGB')
        label = self.labels[idx]
        if self.transform:
            img = self.transform(img)
        return img, label

print("‚úÖ Dataset class defined successfully!")

# ============================================================================
# CELL 4: VISUALIZATION - RAW IMAGES
# ============================================================================
def visualize_raw_images(image_files, labels, num_samples=6):
    """Visualize raw images before preprocessing"""
    class_names = ['Normal', 'Benign', 'Malignant']

    if len(image_files) == 0:
        print("‚ùå No images to visualize!")
        return

    if len(image_files) < num_samples:
        num_samples = len(image_files)

    # ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ random.sample ÿ®ÿØŸÑÿßŸã ŸÖŸÜ numpy.random.choice
    indices = random.sample(range(len(image_files)), num_samples)

    fig, axes = plt.subplots(2, 3, figsize=(15, 8))
    axes = axes.ravel()

    for i, idx in enumerate(indices):
        img = Image.open(image_files[idx]).convert('RGB')
        axes[i].imshow(img)
        axes[i].set_title(f"{class_names[labels[idx]]}", fontsize=14, fontweight='bold')
        axes[i].axis('off')

    plt.suptitle("Raw Images (Before Preprocessing)", fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.show()

# Run visualization automatically
if len(train_files) > 0:
    print("üì∏ Visualizing raw images...")
    visualize_raw_images(train_files, train_labels, num_samples=6)
else:
    print("‚ö†Ô∏è No data available for visualization")

# ============================================================================
# CELL 5: VISUALIZATION - CLASS DISTRIBUTION
# ============================================================================
def visualize_class_distribution(labels):
    """Visualize class distribution"""
    if len(labels) == 0:
        print("‚ùå No labels to visualize!")
        return

    class_names = ['Normal', 'Benign', 'Malignant']
    counts = [labels.count(i) for i in range(3)]

    plt.figure(figsize=(10, 6))
    bars = plt.bar(class_names, counts, color=['green', 'orange', 'red'], alpha=0.7)
    plt.title("Class Distribution", fontsize=16, fontweight='bold')
    plt.ylabel("Number of Images", fontsize=12)
    plt.xlabel("Class", fontsize=12)

    # Add value labels on bars
    for bar, count in zip(bars, counts):
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height,
                f'{count}',
                ha='center', va='bottom', fontsize=12, fontweight='bold')

    plt.grid(axis='y', alpha=0.3)
    plt.tight_layout()
    plt.show()

# Run visualization automatically
if len(train_labels) > 0:
    print("üìä Visualizing class distribution...")
    visualize_class_distribution(train_labels)
else:
    print("‚ö†Ô∏è No data available for visualization")

# ============================================================================
# CELL 6: CREATE DATASETS WITH TRANSFORMS
# ============================================================================
# Define transforms
train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(p=0.3),
    transforms.RandomRotation(10),
    transforms.ColorJitter(brightness=0.2, contrast=0.2),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

test_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Create datasets
if len(train_files) > 0:
    train_dataset = BreastCancerDataset(train_files, train_labels, train_transform)
    val_dataset = BreastCancerDataset(val_files, val_labels, test_transform)
    test_dataset = BreastCancerDataset(test_files, test_labels, test_transform)
    print("‚úÖ Datasets created successfully!")
    print(f"   Train dataset: {len(train_dataset)} images")
    print(f"   Validation dataset: {len(val_dataset)} images")
    print(f"   Test dataset: {len(test_dataset)} images")
else:
    print("‚ö†Ô∏è Cannot create datasets - no data loaded")

# ============================================================================
# CELL 7: VISUALIZATION - TRANSFORMED IMAGES
# ============================================================================
def visualize_after_transforms(dataset, num_samples=6):
    """Visualize images after transforms"""
    class_names = ['Normal', 'Benign', 'Malignant']

    if len(dataset) == 0:
        print("‚ùå Dataset is empty!")
        return

    if len(dataset) < num_samples:
        num_samples = len(dataset)

    # ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ random.sample ÿ®ÿØŸÑÿßŸã ŸÖŸÜ numpy.random.choice
    indices = random.sample(range(len(dataset)), num_samples)

    fig, axes = plt.subplots(2, 3, figsize=(15, 8))
    axes = axes.ravel()

    for i, idx in enumerate(indices):
        img, label = dataset[idx]

        # Denormalize
        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)
        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)
        img = img * std + mean
        img = torch.clamp(img, 0, 1)
        img = img.permute(1, 2, 0)

        axes[i].imshow(img)
        axes[i].set_title(f"{class_names[label]}", fontsize=14, fontweight='bold')
        axes[i].axis('off')

    plt.suptitle("Images After Transforms (Model Input)", fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.show()

# Run visualization automatically
if len(train_files) > 0:
    print("üîÑ Visualizing transformed images...")
    visualize_after_transforms(train_dataset, num_samples=6)
else:
    print("‚ö†Ô∏è No data available for visualization")

class ResNetClassifier(nn.Module):
    """ResNet18-based classifier for breast cancer detection"""
    def __init__(self, num_classes=3):
        super(ResNetClassifier, self).__init__()
        self.resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)

        num_features = self.resnet.fc.in_features
        self.resnet.fc = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(num_features, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, num_classes)
        )

    def forward(self, x):
        return self.resnet(x)

print("‚úÖ Model architecture defined successfully!")

# ============================================================================
# CELL 9: TRAINING FUNCTION
# ============================================================================
def train_model_with_epochs(model, train_loader, val_loader, num_epochs=30):
    """Train the model and track progress"""
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)

    # Training history
    train_loss_history = []
    val_loss_history = []
    train_acc_history = []
    val_acc_history = []
    learning_rates = []

    print(f"üöÄ Starting training for {num_epochs} epochs...")
    print("-" * 80)

    best_val_acc = 0.0

    for epoch in range(num_epochs):
        # Training phase
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0

        for batch_idx, (images, labels) in enumerate(train_loader):
            images, labels = images.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

            # Print progress every 10 batches
            if (batch_idx + 1) % 10 == 0:
                current_loss = loss.item()
                batch_acc = (predicted == labels).sum().item() / labels.size(0) * 100
                print(f'Epoch [{epoch+1:2d}/{num_epochs}] | '
                      f'Batch [{batch_idx+1:3d}/{len(train_loader):3d}] | '
                      f'Loss: {current_loss:.4f} | '
                      f'Acc: {batch_acc:.1f}%')

        train_loss = running_loss / len(train_loader)
        train_acc = 100.0 * correct / total
        train_loss_history.append(train_loss)
        train_acc_history.append(train_acc)

        # Validation phase
        model.eval()
        val_running_loss = 0.0
        val_correct = 0
        val_total = 0

        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                loss = criterion(outputs, labels)

                val_running_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                val_total += labels.size(0)
                val_correct += (predicted == labels).sum().item()

        val_loss = val_running_loss / len(val_loader)
        val_acc = 100.0 * val_correct / val_total
        val_loss_history.append(val_loss)
        val_acc_history.append(val_acc)

        # Update learning rate
        scheduler.step(val_loss)
        current_lr = optimizer.param_groups[0]['lr']
        learning_rates.append(current_lr)

        # Save best model
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            torch.save(model.state_dict(), 'best_model.pth')
            print(f"‚úÖ Saved best model at epoch {epoch+1} (Val Acc: {val_acc:.2f}%)")

        # Print epoch summary
        print(f"\n{'='*80}")
        print(f"Epoch {epoch+1}/{num_epochs} Summary:")
        print(f"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%")
        print(f"  Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.2f}%")
        print(f"  Learning Rate: {current_lr:.6f}")
        print(f"  Best Val Acc:  {best_val_acc:.2f}%")
        print(f"{'='*80}\n")

    # Load best model
    model.load_state_dict(torch.load('best_model.pth'))
    print(f"\nüéØ Training completed! Best validation accuracy: {best_val_acc:.2f}%")

    return {
        'model': model,
        'train_loss_history': train_loss_history,
        'val_loss_history': val_loss_history,
        'train_acc_history': train_acc_history,
        'val_acc_history': val_acc_history,
        'learning_rates': learning_rates
    }

print("‚úÖ Training function defined successfully!")

# ============================================================================
# CELL 10: RUN TRAINING (ÿ™ÿ¥ÿ∫ŸäŸÑ ÿßŸÑÿ™ÿØÿ±Ÿäÿ® ÿ™ŸÑŸÇÿßÿ¶ŸäÿßŸã)
# ============================================================================
# Configuration
NUM_EPOCHS = 30  # ŸäŸÖŸÉŸÜŸÉ ÿ™ÿ∫ŸäŸäÿ± ÿπÿØÿØ ÿßŸÑŸÄ epochs ŸáŸÜÿß
BATCH_SIZE = 32

print("="*80)
print("üöÄ STARTING AUTOMATIC TRAINING")
print("="*80)

if len(train_files) > 0:
    # Create dataloaders
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)
    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)

    print(f"‚úÖ DataLoaders created")
    print(f"   Batch size: {BATCH_SIZE}")
    print(f"   Train batches: {len(train_loader)}")
    print(f"   Val batches: {len(val_loader)}")
    print(f"   Test batches: {len(test_loader)}")

    # Initialize model
    print("\nüß† Initializing model...")
    model = ResNetClassifier(num_classes=3).to(device)
    print(f"   Total parameters: {sum(p.numel() for p in model.parameters()):,}")
    print(f"   Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")

    # Train model
    print(f"\nüèãÔ∏è Training model for {NUM_EPOCHS} epochs...")
    training_results = train_model_with_epochs(model, train_loader, val_loader, num_epochs=NUM_EPOCHS)

    # Save final model
    print("\nüíæ Saving trained model...")
    torch.save({
        'model_state_dict': training_results['model'].state_dict(),
        'class_names': ['Normal', 'Benign', 'Malignant'],
        'transform_info': {
            'resize': (224, 224),
            'mean': [0.485, 0.456, 0.406],
            'std': [0.229, 0.224, 0.225]
        }
    }, 'trained_model.pth')

    print("‚úÖ Model saved as 'trained_model.pth'")
    print("‚úÖ Best model saved as 'best_model.pth'")
    print("\n" + "="*80)
    print("üéâ TRAINING COMPLETED SUCCESSFULLY!")
    print("="*80)
else:
    print("‚ùå Cannot train - no data loaded!")

# ============================================================================
# CELL 11: VISUALIZATION - TRAINING HISTORY
# ============================================================================
def plot_training_history(training_results):
    """Plot training history"""
    train_loss = training_results['train_loss_history']
    val_loss = training_results['val_loss_history']
    train_acc = training_results['train_acc_history']
    val_acc = training_results['val_acc_history']
    learning_rates = training_results['learning_rates']

    epochs = range(1, len(train_loss) + 1)

    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))

    # Plot 1: Training and Validation Loss
    ax1.plot(epochs, train_loss, 'b-', label='Training Loss', linewidth=2)
    ax1.plot(epochs, val_loss, 'r-', label='Validation Loss', linewidth=2)
    ax1.set_xlabel('Epochs', fontsize=12)
    ax1.set_ylabel('Loss', fontsize=12)
    ax1.set_title('Training and Validation Loss', fontsize=14, fontweight='bold')
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # Plot 2: Training and Validation Accuracy
    ax2.plot(epochs, train_acc, 'b-', label='Training Accuracy', linewidth=2)
    ax2.plot(epochs, val_acc, 'r-', label='Validation Accuracy', linewidth=2)
    ax2.set_xlabel('Epochs', fontsize=12)
    ax2.set_ylabel('Accuracy (%)', fontsize=12)
    ax2.set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')
    ax2.legend()
    ax2.grid(True, alpha=0.3)

    # Plot 3: Learning Rate Schedule
    ax3.plot(epochs, learning_rates, 'g-', linewidth=2, marker='o', markersize=4)
    ax3.set_xlabel('Epochs', fontsize=12)
    ax3.set_ylabel('Learning Rate', fontsize=12)
    ax3.set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')
    ax3.grid(True, alpha=0.3)
    ax3.set_yscale('log')

    # Plot 4: Loss vs Accuracy
    ax4.scatter(train_acc, train_loss, alpha=0.5, label='Training', s=50)
    ax4.scatter(val_acc, val_loss, alpha=0.5, label='Validation', s=50)
    ax4.set_xlabel('Accuracy (%)', fontsize=12)
    ax4.set_ylabel('Loss', fontsize=12)
    ax4.set_title('Loss vs Accuracy', fontsize=14, fontweight='bold')
    ax4.legend()
    ax4.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

# Run visualization automatically if training was successful
if 'training_results' in locals():
    print("üìà Visualizing training history...")
    plot_training_history(training_results)
else:
    print("‚ö†Ô∏è No training results available for visualization")

# ============================================================================
# CELL 12: VISUALIZATION - MODEL PREDICTIONS
# ============================================================================
def visualize_predictions(model, test_loader, num_samples=6):
    """Visualize model predictions"""
    model.eval()
    class_names = ['Normal', 'Benign', 'Malignant']

    # Get a batch
    images, labels = next(iter(test_loader))

    if images.size(0) < num_samples:
        num_samples = images.size(0)

    images = images[:num_samples].to(device)
    labels = labels[:num_samples]

    # Get predictions
    with torch.no_grad():
        outputs = model(images)
        probabilities = F.softmax(outputs, dim=1)
        _, predictions = torch.max(outputs, 1)

    # Create visualization
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    axes = axes.ravel()

    for i in range(num_samples):
        # Denormalize image
        img = images[i].cpu()
        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)
        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)
        img = img * std + mean
        img = torch.clamp(img, 0, 1)
        img = img.permute(1, 2, 0)

        axes[i].imshow(img)

        true_label = class_names[labels[i].item()]
        pred_label = class_names[predictions[i].item()]
        confidence = probabilities[i][predictions[i]].item()

        # Color code based on correctness
        color = 'green' if true_label == pred_label else 'red'

        axes[i].set_title(
            f"True: {true_label}\nPred: {pred_label}\nConf: {confidence:.2%}",
            color=color, fontsize=10, fontweight='bold'
        )
        axes[i].axis('off')

    plt.suptitle('Model Predictions on Test Samples', fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.show()

# Run visualization automatically if model exists
if 'training_results' in locals() and len(test_files) > 0:
    print("üîç Visualizing model predictions...")
    visualize_predictions(training_results['model'], test_loader, num_samples=6)
else:
    print("‚ö†Ô∏è No trained model available for predictions visualization")

from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import torch

def show_confusion_matrix(model, test_loader, device):
    model.eval()
    class_names = ['Normal', 'Benign', 'Malignant']

    y_true = []
    y_pred = []

    with torch.no_grad():
        for images, labels in test_loader:
            images = images.to(device)
            outputs = model(images)
            _, preds = torch.max(outputs, 1)

            y_true.extend(labels.cpu().numpy())
            y_pred.extend(preds.cpu().numpy())

    # Confusion Matrix
    cm = confusion_matrix(y_true, y_pred)

    # Plot
    plt.figure(figsize=(6, 5))
    sns.heatmap(
        cm,
        annot=True,
        fmt='d',
        cmap='Blues',
        xticklabels=class_names,
        yticklabels=class_names
    )
    plt.xlabel("Predicted Label")
    plt.ylabel("True Label")
    plt.title("Confusion Matrix")
    plt.tight_layout()
    plt.show()

    return cm

cm = show_confusion_matrix(training_results['model'], test_loader, device)

# ============================================================================
# CELL 14: LOAD TRAINED MODEL (ŸÑŸÑÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ŸÅŸä GUI)
# ============================================================================
def load_trained_model(model_path='/content/best_model.pth'):
    """Load a trained model for inference"""

    # Check if model exists
    if not os.path.exists(model_path):
        print(f"‚ùå Model file not found: {model_path}")
        print("Looking for model in common locations...")

        # Check other possible locations
        possible_paths = [
            'best_model.pth',
            './trained_model.pth',
            './best_model.pth',
            '/kaggle/working/trained_model.pth',
            '/kaggle/working/best_model.pth',
            '/content/trained_model.pth',
            '/content/best_model.pth'
        ]

        for path in possible_paths:
            if os.path.exists(path):
                model_path = path
                print(f"‚úÖ Found model at: {path}")
                break
        else:
            print("‚ùå No model found. Please run training first (Cell 10).")
            return None

    try:
        model = ResNetClassifier(num_classes=3).to(device)

        # Load checkpoint
        checkpoint = torch.load(model_path, map_location=device, weights_only=False)

        # Check if it's a full checkpoint or just state dict
        if 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
        else:
            model.load_state_dict(checkpoint)

        model.eval()
        print(f"‚úÖ Model loaded successfully from {model_path}")
        return model

    except Exception as e:
        print(f"‚ùå Error loading model: {str(e)}")
        return None

# Load model automatically
print("üîÑ Loading trained model for GUI...")
gui_model = load_trained_model()

if gui_model:
    print("‚úÖ Model ready for GUI!")
else:
    print("‚ö†Ô∏è Model not loaded. GUI will not work properly.")

# ============================================================================
# CELL 15: GRADIO GUI - PREDICTION INTERFACE
# ============================================================================
def predict_image(image):
    """Predict on a single image"""
    try:
        if image is None:
            return "‚ö†Ô∏è Please upload an image first.", None, {}

        if gui_model is None:
            return "‚ö†Ô∏è Model not loaded. Please run training first (Cell 10).", None, {}

        # Transform image
        transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])

        image_tensor = transform(image).unsqueeze(0).to(device)

        # Predict
        gui_model.eval()
        with torch.no_grad():
            outputs = gui_model(image_tensor)
            probabilities = F.softmax(outputs, dim=1)
            confidence, predicted_idx = torch.max(probabilities, 1)

        class_names = ['Normal', 'Benign', 'Malignant']
        predicted_class = class_names[predicted_idx.item()]
        confidence_score = confidence.item()

        # Create probability plot
        fig, ax = plt.subplots(figsize=(8, 4))
        colors = ['green', 'orange', 'red']
        y_pos = torch.arange(len(class_names))
        probs = probabilities.cpu().squeeze()

        bars = ax.barh(y_pos, probs, color=colors, alpha=0.7)
        ax.set_yticks(y_pos)
        ax.set_yticklabels(class_names, fontsize=12)
        ax.set_xlabel('Probability', fontsize=12)
        ax.set_title(f'Prediction: {predicted_class} ({confidence_score:.2%})',
                    fontsize=14, fontweight='bold')
        ax.set_xlim([0, 1])

        # Add value labels
        for bar, prob in zip(bars, probs):
            width = bar.get_width()
            ax.text(width + 0.01, bar.get_y() + bar.get_height()/2,
                   f'{prob.item():.2%}', ha='left', va='center', fontweight='bold')

        plt.tight_layout()

        # Prepare results
        if predicted_class == 'Normal':
            detection_result = "‚úÖ NO CANCER DETECTED"
            recommendation = "Routine follow-up recommended"
            color = "#d4edda"
            border_color = "#c3e6cb"
            text_color = "#155724"
        elif predicted_class == 'Benign':
            detection_result = "‚ö†Ô∏è BENIGN TUMOR DETECTED"
            recommendation = "Non-cancerous tumor. Regular monitoring advised."
            color = "#fff3cd"
            border_color = "#ffeaa7"
            text_color = "#856404"
        else:
            detection_result = "üö® MALIGNANT CANCER DETECTED"
            recommendation = "URGENT: Consult oncologist immediately!"
            color = "#f8d7da"
            border_color = "#f5c6cb"
            text_color = "#721c24"

        results_html = f"""
        <div style="background-color: {color}; padding: 20px; border-radius: 10px; border: 2px solid {border_color};">
            <h2 style="color: {text_color};">{detection_result}</h2>
            <p><strong>üîç Prediction:</strong> {predicted_class}</p>
            <p><strong>üìä Confidence:</strong> {confidence_score:.2%}</p>
            <p><strong>üß¨ Cancer Detected:</strong> {'‚úÖ NO' if predicted_class == 'Normal' else '‚ö†Ô∏è YES (Benign)' if predicted_class == 'Benign' else 'üö® YES (Malignant)'}</p>
            <hr>
            <h3>üí° Recommendation:</h3>
            <p>{recommendation}</p>
            <p style="font-size: 12px; margin-top: 15px; color: #666;">
                <strong>Disclaimer:</strong> This is for educational purposes only. Always consult a medical professional.
            </p>
        </div>
        """

        results_json = {
            'class': predicted_class,
            'confidence': float(confidence_score),
            'probabilities': {
                'Normal': float(probs[0]),
                'Benign': float(probs[1]),
                'Malignant': float(probs[2])
            },
            'detection': detection_result,
            'recommendation': recommendation,
            'is_cancer': predicted_class != 'Normal'
        }

        return results_html, fig, results_json

    except Exception as e:
        error_msg = f"‚ùå Error during prediction: {str(e)}"
        print(error_msg)
        return error_msg, None, {}


def create_gradio_interface():
    """Create Gradio interface for prediction"""

    with gr.Blocks(theme=gr.themes.Soft(), title="Breast Cancer Detection AI") as demo:

        # Title
        gr.Markdown("# üß¨ Breast Cancer Detection AI")
        gr.Markdown("### Ultrasound Image Classification System")

        # Disclaimer
        gr.Markdown("""
        <div style="background-color: #fff3cd; padding: 15px; border-radius: 5px; border: 1px solid #ffeaa7; margin: 15px 0;">
            <h3>‚ö†Ô∏è IMPORTANT DISCLAIMER</h3>
            <p><strong>For educational and research purposes only.</strong> NOT for medical diagnosis.</p>
            <p>Always consult qualified healthcare professionals for medical advice.</p>
        </div>
        """)

        with gr.Row():
            with gr.Column(scale=1):
                image_input = gr.Image(
                    label="üì§ Upload Ultrasound Image",
                    type="pil",
                    height=300
                )

                with gr.Row():
                    predict_btn = gr.Button("üîç Analyze Image", variant="primary", size="lg")
                    clear_btn = gr.Button("üîÑ Clear", size="lg")

            with gr.Column(scale=1):
                results_output = gr.HTML(label="üìã Analysis Results")
                probability_plot = gr.Plot(label="üìä Prediction Probabilities")
                json_output = gr.JSON(label="üìÅ Detailed Results (JSON)")

        # Connect buttons
        predict_btn.click(
            fn=predict_image,
            inputs=[image_input],
            outputs=[results_output, probability_plot, json_output]
        )

        def clear_all():
            return None, "## Upload an image and click 'Analyze Image'", None, {}

        clear_btn.click(
            fn=clear_all,
            outputs=[image_input, results_output, probability_plot, json_output]
        )

        # Instructions
        gr.Markdown("""
        ## üìñ How to Use:
        1. **Upload** an ultrasound image using the upload button
        2. **Click** "Analyze Image" to get predictions
        3. **View** the results, probability distribution, and detailed JSON output
        4. **Clear** the interface using the Clear button

        ## üè• Classes:
        - **Normal**: No cancer detected
        - **Benign**: Non-cancerous tumor detected
        - **Malignant**: Cancerous tumor detected

        ## ‚ö†Ô∏è Important Notes:
        - Model accuracy depends on training data quality
        - Results are for educational purposes only
        - Always consult medical professionals for diagnosis
        """)

        # Additional info
        gr.Markdown("""
        <div style="background-color: #e3f2fd; padding: 10px; border-radius: 5px; margin-top: 20px;">
            <h4>üì¢ For Kaggle/Colab Users:</h4>
            <p>After clicking "Run" below, wait for the public URL to appear.</p>
            <p>Click on the URL ending with <code>*.gradio.live</code> to open the interface.</p>
        </div>
        """)

    return demo


# Launch GUI automatically
print("\n" + "="*80)
print("üöÄ LAUNCHING GRADIO GUI")
print("="*80)

if gui_model is not None:
    try:
        print("üîó Creating Gradio interface...")
        demo = create_gradio_interface()

        print("üåê Launching interface...")
        print("üì¢ Look for the public URL ending with '*.gradio.live'")
        print("‚è≥ This may take a few moments...")

        # Launch with public URL
        demo.launch(
            share=True,
            debug=False,
            server_name="0.0.0.0",
            server_port=7861,
            show_error=True
        )

    except Exception as e:
        print(f"‚ö†Ô∏è Launch error: {e}")
        print("Trying alternative launch method...")
        try:
            demo.launch(share=True, server_port=8080, debug=True)
        except Exception as e2:
            print(f"‚ùå Could not launch GUI: {e2}")
else:
    print("‚ùå Cannot launch GUI - Model not loaded!")
    print("Please run Cell 10 to train the model first.")